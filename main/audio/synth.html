<HTML>
<!-- Mirrored from hyperphysics.phy-astr.gsu.edu/hbase/audio/synth.html by HTTrack Website Copier/3.x [XR&CO'2010], Sun, 25 Dec 2011 05:44:31 GMT -->
<HEAD>   <TITLE>Sound Synthesis</TITLE></HEAD><body bgcolor="#FFE4C8"><!-- Copyright 1999 by Carl Rod Nave, RodNave@gsu.edu--><A Name="c1"></A><TABLE WIDTH="580" HEIGHT="370" BORDER="1" CELLSPACING="2" CELLPADDING="2"><TR><TD WIDTH="514" HEIGHT="309"><H1 align=center>Sound Synthesis</H1> <p> Periodic electric signals can be converted into sound by amplifying them and driving a loudspeaker with them. One way to do this is to simply add various amplitudes of the harmonics of a chosen pitch until the desired <a href="../sound/timbre.html#c1">timbre</a> is obtained, called additive synthesis. Another way is to start with <a href="geowv.html#c1">geometric waves</a>, which are rich in harmonic content, and filter the harmonics to produce a new sound- subtractive synthesis. </p>     <p>Modern sound synthesis makes increasing use of <a href="#c3">MIDI</a> for sequencing and communication between devices.  </p><center><table BORDER="1" CELLSPACING="2" CELLPADDING="2"><tr><td><a href="#c2">Methods of synthesis</a></td></tr></table></center></TD><TD WIDTH="66" align=center><a href="../hframe.html">Index</a><BR><BR><a href="audiocon.html#c1">Sound reproduction concepts</a></TD></TR><TR><TD HEIGHT="17">&nbsp;<A HREF="../hph.html"> HyperPhysics</A>*****<A HREF="../sound/soucon.html">     Sound </A></TD><TD><a href="Javascript:history.go(-1)">Go Back</a></TD></TR></TABLE><BR><BR><BR><BR><BR><BR><BR><BR><A Name="c2"></A><TABLE WIDTH="580" HEIGHT="370" BORDER="1" CELLSPACING="2" CELLPADDING="2"><TR><TD WIDTH="514" HEIGHT="309"><H1 align=center>Methods of Synthesis</H1> <p> Jeff Pressing in "Synthesizer Performance and Real-Time Techniques" gives this list of approaches to sound synthesis. </p><ul><li>additive synthesis   -  combining tones, typically harmonics of varying amplitudes </li>        <li>subtractive synthesis  - filtering of complex sounds to shape<a href="../sound/timbre.html#c2"> harmonic</a> spectrum, typically starting      with <a href="geowv.html#c1">geometric waves</a>. </li>                             <li>frequency modulation synthesis - modulating a carrier wave with one or more operators</li><li>sampling - using recorded sounds as sound sources subject to modification</li><li>composite synthesis - using artificial and sampled sounds to establish resultant "new" sound</li><li>phase distortion - altering speed of waveforms stored in wavetables during playback</li><li>waveshaping - intentional distortion of a signal to produce a modified result</li><li>resynthesis - modification of digitally sampled sounds before playback</li><li>granular synthesis - combining of several small sound segments into a new sound</li><li>linear predictive coding - technique for speech synthesis</li><li>direct digital synthesis - computer modification of generated waveforms</li><li>wave sequencing - linear combinations of severtal small segments to create a new sound</li><li>vector synthesis - technique for fading between any number of different sound sources</li><li>physical modeling - mathematical equations of acoustic characteristics of sound</li></ul><center><table BORDER="1" CELLSPACING="2" CELLPADDING="2"><tr><td><a href="#c1">Sound synthesis</a></td></tr></table></center></TD><TD WIDTH="66" align=center><a href="../hframe.html">Index</a><BR><BR><a href="audiocon.html#c1">Sound reproduction concepts</a><BR><BR>Reference<br><a href="../sound/souref.html#c1">Pressing</a></TD></TR><TR><TD HEIGHT="17">&nbsp;<A HREF="../hph.html"> HyperPhysics</A>*****<A HREF="../sound/soucon.html">     Sound </A></TD><TD><a href="Javascript:history.go(-1)">Go Back</a></TD></TR></TABLE><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><A Name="c3"></A><TABLE WIDTH="580" HEIGHT="370" BORDER="1" CELLSPACING="2" CELLPADDING="2"><TR><TD WIDTH="514" HEIGHT="309"><H1 align=center>MIDI for Music</H1><p>      Musical Instrument Digital Interface (MIDI) is a <a href="../electronic/serial.html#c4">data transfer</a> protocol which is widely used with music synthesizers. MIDI can be used as a controller between modules in an integrated music system. It uses a serial data connection with five leads. It uses two basic message types - channel and system. Channel messages can be sent from machine to machine over any one of 16 channels to control an instrument's voice parameters or to control the way the instrument responds to voice messages. System messages can be directed to all devices in the system (called "common" messages) or can be directed to a specific machine (exclusive). Within the MIDI protocol, a basic set of standards has been developed called the General MIDI specification, or just GM. It attempts to standardize common practices within MIDI and make it more accessible to the general user. GM is particularly appropriate for a personal computer-based MIDI system using a sound card in the computer. Part of the GM standard requires support for a basic set of 128 instruments, a minimum of 24-voice polyphony, and polytimbrality to at least 16 sounds deep. </p>      <p>  Using a MIDI sequencer to control one or more instruments has some significant practical benefits. A MIDI sequence which plays several minutes of music can be stored in a few kilobytes of memory on a computer, whereas the storage of a minute's worth of digitally precise and clear CD quality music directly on a computer disc might take 10 MB of memory.  The MIDI file is just a digital representation of the sequence of notes with information about pitch, duration, voice, etc., and that takes much less memory than the digitally recorded image of the complex sound.</p>      <p> Other practical benefits include the ability to transpose music without changing its duration, to change its tempo without changing its pitch, or change the synthetic instruments used to perform the piece of music. Drawbacks include the inability to easily include a recorded voice part or  played instrument along with the MIDI sequenced sound, but on the other hand, the music can be easily synchronized with multimedia events in a production. </p> </TD><TD WIDTH="66" align=center><a href="../hframe.html">Index</a><BR><BR><a href="audiocon.html#c1">Sound reproduction concepts</a></TD></TR><TR><TD HEIGHT="17">&nbsp;<A HREF="../hph.html"> HyperPhysics</A>*****<A HREF="../sound/soucon.html">     Sound </A></TD><TD><a href="Javascript:history.go(-1)">Go Back</a></TD></TR></TABLE><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></BODY>
<!-- Mirrored from hyperphysics.phy-astr.gsu.edu/hbase/audio/synth.html by HTTrack Website Copier/3.x [XR&CO'2010], Sun, 25 Dec 2011 05:44:31 GMT -->
</HTML>