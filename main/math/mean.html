<HTML>
<!-- Mirrored from hyperphysics.phy-astr.gsu.edu/hbase/math/mean.html by HTTrack Website Copier/3.x [XR&CO'2010], Sun, 25 Dec 2011 07:26:51 GMT -->
<HEAD>   <TITLE>Mean or Expectation Value</TITLE></HEAD><body bgcolor="#FFE4C8"><!-- Copyright 2001 by Carl Rod Nave, RodNave@gsu.edu--><A Name="c1"></A><TABLE WIDTH="580" HEIGHT="370" BORDER="1" CELLSPACING="2" CELLPADDING="2"><TR><TD WIDTH="514" HEIGHT="309"><H1 align=center>The Mean</H1> <p>The value you expect to get in a statistical experiment is the mean. If you toss a coin 10 times, you expect to get 5 heads and 5 tails. The mean is often called the "expected value" or the "expectation value". You expect this value because the probability of getting "heads" is 0.5 and if you toss 10 times you should get 5. To formalize this particular example of the mean, if p is the probability and n the number of events, then the mean is a = np. This is the form of the mean when the probability can be expressed by the <a href="disfcn.html#c2">binomial distribution</a>.</p><p>To formalize the concept a bit more, if for an experiment with discrete outcomes x<sub>i</sub> for which the probability is P(x<sub>i</sub>), then the mean is given by</p><center><font size="+1"><p>a =  <font size="+2"><font face="symbol">S</font></font>x<sub>i</sub>P(x<sub>i</sub>)</font></center></p><p>For the case of continuous variables where the probability is expressed in terms of a <a href="probas.html#c2">distribution function</a>, the mean takes the form</p><center><img src="immath/mean.gif"></center><br><center><table BORDER="1" CELLSPACING="2" CELLPADDING="2"><tr><td><center><a href="../kinetic/bolapp.html#c2">Mean particle energy from Boltzmann distribution</a></center></td></tr><tr><td><center><a href="#c2">Mean value for binomial distribution</a></center></td></tr><tr><td><center><a href="../nuclear/meanlif.html#c1">Mean lifetime for particle decay</a></center></td></tr></table></center></TD><TD WIDTH="66" align=center><a href="../hframe.html">Index</a><br><br><a href="statcon.html#c1">Applied statistics concepts</a></TD></TR><TR><TD HEIGHT="17">&nbsp;<table><tr><td width= "450"><A HREF="../hph.html"> HyperPhysics</A>*****<a href="../hmat.html#hmath">HyperMath</a>*****<A HREF="../alg.html#exp">Algebra</A></td><td align=right><font size="-1"><i>R Nave</i></font></td></tr></table></TD><TD><a href="Javascript:history.go(-1)">Go Back</a></TD></TR></TABLE><BR><BR><BR><BR><BR><BR><BR><A Name="c2"></A><TABLE WIDTH="580" HEIGHT="370" BORDER="1" CELLSPACING="2" CELLPADDING="2"><TR><TD WIDTH="514" HEIGHT="309"><H1 align=center>The Mean of the Binomial Distribution</H1> <p>The mean value of the <a href="disfcn.html#c2">binomial distribution</a>  is a = np where n is the number of events and p is the probability for each event. </p><center><table><tr><td>Binomial distribution:</td><td><img src="immath/binfcn.gif"></td><td>Mean:</td><td><img src="immath/np.gif"></td></tr></table></center><p>This seems a very simple expression for the mean of such a complicated function, but the result agrees with our intuition. If you throw a die, hoping to throw a "2", then the probability is 1/6. If you throw it 6 times, you would expect to get one throw with value "2". The mean or expected value for 6 throws is  (1/6)(6) = 1. For such a simple expression, the proof that it is in fact the mean is rather involved. The following approach is after Appendix D of Rohlf's Modern Physics. </p><p>From the definition of the <a href="#c1">mean</a> using a <a href="probas.html#c2">distribution function</a>, the binomial mean is</p><center><img src="immath/meanbin1.gif"></center><p>The goal is to reduce this expression to just np. Since the first term in the sum is zero, since x=0, we can replace the sum with a sum starting from 1.</p><center><img src="immath/meanbin2.gif"></center><p>Now cancel the common factor of x appearing in numerator and denominator.</p><center><img src="immath/meanbin3.gif"></center><p>Since the summation index is a dummy variable, we make the change of variables x' = x - 1.</p><center><img src="immath/meanbin4.gif"></center><p>Now factor out np.</p><center><img src="immath/meanbin5.gif"></center><p>The terms in the summation above are just the binomial function for n-1 trials, and you are summing it over all values of x - so that sum must be just 1. The expression then reduces to the desired expression for the mean.</p><center><table><tr><td><img src="immath/meanbin6.gif"></td><td>Mean of the<br>binomial distribution.</td></tr></table></center><p>Since the <a href="gaufcn.html#c1">Gaussian</a> and <a href="poifcn.html#c1">Poisson distributions</a> are approximations to the binomial distribution, this expression for the mean applies to them as well.</p></TD><TD WIDTH="66" align=center><a href="../hframe.html">Index</a><br><br><a href="statcon.html#c1">Applied statistics concepts</a><br><br>Reference<br><a href="../quaref.html#c1">Rohlf</a><br>App. D. </TD></TR><TR><TD HEIGHT="17">&nbsp;<table><tr><td width= "450"><A HREF="../hph.html"> HyperPhysics</A>*****<a href="../hmat.html#hmath">HyperMath</a>*****<A HREF="../alg.html#exp">Algebra</A></td><td align=right><font size="-1"><i>R Nave</i></font></td></tr></table></TD><TD><a href="Javascript:history.go(-1)">Go Back</a></TD></TR></TABLE><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR><BR></BODY>
<!-- Mirrored from hyperphysics.phy-astr.gsu.edu/hbase/math/mean.html by HTTrack Website Copier/3.x [XR&CO'2010], Sun, 25 Dec 2011 07:26:55 GMT -->
</HTML>